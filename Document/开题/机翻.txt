LARGE SCALE METRIC LEARNING FOR MUSIC SIMILARITY
Daniel {Rosenberg, Erenrich}

ABSTRACT
Automatic music classification is an important problem in music analysis. In this paper, we use data from the “Million Song Dataset” to construct and evaluate music similarity metrics and metric learning techniques. While others have done metric learning on music datasets before, we evaluate which standard techniques perform best in both accuracy and time on this much larger dataset. We find that dramatically increasing the dataset size leads to larger performance gains than one might expect.

INTRODUCTION
Machine music analysis is a growing field in both industry and academia. One of the major difficulties with this work is that it requires large labeled corpora which are difficult to obtain. The relatively new “Million Song Dataset” provides the music analysis community an opportunity to scale research to very large datasets with little organizational difficulty [2]. Already many papers have capitalized on this data to solve such problems as playlist generation [4], music classification and song cover-identification [1].

Music similarity algorithms are especially useful because they can be used as subcomponents of algorithms like cover identification and playlist generation. Previous work on music analysis was often performed on datasets as small as just 5000 songs [5]. It is now important that we reevaluate these techniques to determine how these algorithms scale in terms of accuracy and speed. It is not immediately obvious that all of our music metric-learning techniques will be able to scale. Others have already shown algorithmic techniques to speed up basic metrics of music similarity [3].

We performed metric learning across the “Million Song Dataset” in order to determine song similarity. Previous work has mainly relied upon definitions of similarity as songs appearing in the same album or being performed by the same artist. Other similarity measures have had poor performance. We take the creating artist as our ground truth for similarity.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.

c 2011 International Society for Music Information Retrieval.

DATA REPRESENTATION
2.1 Audio representation
The “Million Song Dataset” provides features and metadata for a million songs as generated by the “Echo Nest’s” music analysis software. This data includes such information as volume, length and beats per minute. In order to fit the entire dataset in memory and effectively work with it we projected down to a much smaller set of features. This set of features was strongly influenced by [5] though we chose to drop several features as they are not consistently populated across the dataset. Less than one percent of the dataset appears to be invalid or improperly populated since some values are clearly incorrect. For example: songs which are listed as having zero beats were dropped from the analysis.


音乐相似性的大规模度量学习
丹尼尔{罗森伯格，艾伦里奇｝
摘要
自动音乐分类是音乐分析中的一个重要问题。
音乐分析中的一个重要问题。在本文中，我们使用 "百万首歌曲数据集 "中的数据来构建和评估音乐相似性度量和度量学习技术。虽然以前也有人在音乐数据集上进行过度量学习，但我们
在这个规模更大的数据集上，我们评估了哪些标准技术在准确性和时间上表现最佳。我们发现
数据集规模的大幅增加所带来的性能提升超出了人们的预期。
1. 引言
在工业界和学术界，机器音乐分析都是一个不断发展的领域。
和学术界都在不断发展。这项工作的主要困难之一是
是它需要大量的标注语料，而这些语料很难获得。
难以获得。相对较新的 "百万首歌曲数据集 "为音乐分析界提供了一个机会，使其可以在组织难度不大的情况下
百万首歌曲数据集 "为音乐分析界提供了一个将研究扩展到超大型数据集的机会，而且在组织方面几乎没有困难[2]。已经有许多论文利用这些数据
来解决播放列表生成 [4]、音乐分类和歌曲封面识别 [5]等问题。
分类和歌曲封面识别等问题[1]。
音乐相似性算法之所以特别有用，是因为
因为它们可以用作封面识别和播放列表生成等算法的子组件。以前的音乐分析工作通常是在小到只有
5000 首歌曲 [5]。现在，我们有必要重新评估这些技术
现在，我们有必要重新评估这些技术，以确定这些算法如何在准确性和速度方面进行扩展。
准确性和速度。我们的所有音乐度量学习方法
我们所有的音乐度量学习技术都能
扩展。其他人已经展示了算法技术，以
加快音乐相似性基本度量的算法技术[3]。
我们在 "百万歌曲
数据集 "进行度量学习，以确定歌曲相似度。以前的
之前的工作主要依赖于将相似性定义为歌曲
出现在同一张专辑中或由
同一歌手演唱。其他的相似性测量方法效果不佳。我们将创作歌手作为相似性的基本事实。
相似性。
允许将本作品的全部或部分内容制作成数字拷贝或打印拷贝，供个人或课堂使用，无需支付任何费用。
复制本作品的全部或部分内容供个人或课堂使用，无需支付任何费用。
但不得为牟利或商业利益而复制或分发，且复制件必须
在第一页上注明本声明和完整的引文。
c 2011 国际音乐信息检索学会。
数据表示 2.1 音频表示 “百万首歌曲数据集”为由“Echo Nest的”音乐分析软件生成的一百万首歌曲提供特征和元数据。这些数据包括如体积、长度和每分钟节拍数等信息。为了将整个数据集放入内存并有效地处理它，我们将其降低到一个相当小的特征集。这个特征集受到[5]的强烈影响，尽管我们选择删除一些特征，因为它们在整个数据集中不一致地出现。少于1%的数据集看起来是无效的或者被错误地填充，因为一些值显然是错误的。例如：被列为没有节拍的歌曲被从分析中删除。 我们还添加了一些从歌曲中得出的特征。我们选择包含音调的协方差矩阵，以了解音调是如何组合在一起的。例如，这应该能捕获一个特定和弦经常出现的情况。我们还包含了共同出现计数，以便我们可以检测那些只是因为出现得很少就与强烈相关联的组合。通过添加最大段最大喧闹程度的四分位数，我们希望能够捕获歌曲随时间的进展。例如，如果一种歌曲类型倾向于靠近结尾有更大的喧闹部分，而另一种则以歌曲主题的安静重复结束，这个特征会捕获这个。
歌曲长度
平均片段长度 - Echo Nest将歌曲划分为长度小于一秒的片段
片段长度方差
平均片段喧闹程度
片段喧闹程度方差
最大片段喧闹程度的第三四分位数 - 这给我们一个关于喧闹程度在片段之间分布的想法
最大片段喧闹程度的第一四分位数
平均片段开始喧闹程度
片段开始喧闹程度方差
节拍间隔方差
Tatum置信度
平均Tatum长度
每拍Tatum数
时间签名
时间签名置信度
歌曲模式
歌曲模式置信度
音调协方差矩阵
音调共同出现计数 通过消除所有随时间变化的特征，我们减少了数据的维度308个数字。这意味着500GB的数据集变成了1GB的大小，因此更容易分析。确切丢失了多少信息在转换过程中是不清楚的。 2.2 数据标签 我们用歌曲艺术家标记我们的数据。如果两首歌曲共享一个公共的艺术家，我们就认为它们是相似的。我们使用这个作为我们对自己性能的基准。
算法 3.1 白化 文献中已经证明，首先对数据集进行白化，以确保数据的协方差矩阵是单位矩阵，可以提高性能。我们使用KNN（使用欧氏距离和余弦相似度）及其白化版本。KNN分类器的距离指标评估将通过判断它能否找到我们预先标记为相似的歌曲来完成。 注意，对于白化，我们在所有特征值中都添加了一个小常数，以减少我们后来取反时较小项的影响。这意味着这里的白化只是一个近似。 在这里，我们展示了使用KNN分类器的结果，这些结果是在数据集的压缩版本上得出的，该版本只包含最常见的500位艺术家和25000首歌曲。我们使用了一个包含5000首歌曲的验证测试集，以减少艺术家的稀疏性。以下是我们的准确性表格。

KNN Euclidean Whitened Cosine Whitened
1 12.3% 19.3% 14.8% 20.3%
3 12.1% 19.0% 14.5% 20.1%
5 11.6% 18.2% 13.5% 19.4%
虽然这些结果比在[5]中呈现的结果要差，后者显示出白化的准确性约为75%，但我们需要注意的是，我们正在运行超过4倍的艺术家。实际上，考虑到我们数据集之间的极端差异，我们的结果永远不会直接可比。

事实上，白化在全面未限制的数据集上表现得非常糟糕。这是可以预期的，因为它是一种完全无监督的技术。

3.2 RCA度量学习 现在我们需要创建一个比欧氏或余弦相似度更复杂的距离概念。白化是一个无监督的过程，所以它没有利用我们可用的所有信息。 为了获得一个更有用的距离度量，我们转向了Mahalanobis度量。在这个度量下，两个向量之间的距离是：d(x, y) = (x − y)0 M(x − y)，其中M是一个正半定矩阵。一种替代的定义使用d(x, y) = ||A(x − y)||2，其中M = A0 A。例如，欧氏距离可以表示为M = I W。我们选择学习一个矩阵A，该矩阵应该通过相关组件分析改善我们的相似度度量。 在RCA下，我们将数据分为‘chucklets’，并基本上在每个chunk上单独进行白化。最后，它会比那些影响力不大的特征更重视那些更相关的特征。 我们在全数据集上的结果总结如下：

Algorithm Accuracy
Constant 0.02%
Euclidean 0.2%
Whitening 0.52%
RCA 15.7%
常数算法，该算法简单地预测最常见的艺术家，始终作为比较的参考。 RCA在这个表格中相比前一个表格的表现更差，因为艺术家的数量也随着数据集大小的增加而增加。 本文的主要重点是数据集大小的重要性。它对测试精度的影响如下图所示。这样的增益是因为更大的数据集提供了更多的信息，使得算法能够更好地学习和预测。然而，我们也需要发出一个警告。为此实验创建训练和测试集是困难的。

随机打乱数据集并提取歌曲意味着你可能会发现一个特定的艺术家只存在于测试集中，这意味着任何算法都无法返回正确答案。

另一个问题是大的测试数据集导致更多的类别（例如艺术家）供选择，这应该会增加错误率。为了解决这个问题，我们可能想要固定我们处理的类别数量，并增加每个类别的示例数量。然而，这不是这个特定数据集的一个选项，因为它遵循一个长尾分布，丢弃那些歌曲较少的艺术家将会丢弃大部分数据集。

事实上，KNN性能随k值的增加而下降，如表3.1所示，这也很有趣。我们真正应该分析的是正确的艺术家出现在前k中的时间的分数。再次，这是因为艺术家数据的稀疏性。将k设置为更大的值意味着我们永远不会选择出现频率较低的艺术家。使用一个更密集的指标，如流派，应该可以解决这个问题，因为每个类别有更多的示例。

结论和未来工作 我们得出的结论是，未来的音乐ML研究必须在这样大的数据集上进行，才能得到相关的结果。性能的增加太剧烈，以至于无法忽视。对于音乐的度量学习是有效的，且似乎是解决查找相似音乐和根据样本歌曲创建推荐的问题的一种通用解决方案。本文中使用的方法的一个缺点是，我们基于创作这个作品的艺术家来确定相似性。一个更有效的系统将是使用推荐引擎的数据来进行度量学习。经常一起喜欢的歌曲（听众共同出现）将被视为相似的。这样我们就不会检测出声音相同但是一起被喜欢的歌曲，这在最终是算法这种类型的主要使用场景。
